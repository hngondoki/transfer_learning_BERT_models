{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Y46t9JGVCm_CuDnbwXKPEVrLuZYfSqRl","timestamp":1744385965518}],"gpuType":"T4","authorship_tag":"ABX9TyPcnOorqqE3ZZXnhkH8HW4p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"86a0238f574f411cb1ec5c5c879d6cc9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4affbcb69fb74ae793191055ee3c1055","IPY_MODEL_cdf12dc39c4d4b6d930b997e33b2a449","IPY_MODEL_4dfa9071423a4d46917eea9ba31f0250"],"layout":"IPY_MODEL_9ee67a0e8aef4b4fb30c21291aa744fc"}},"4affbcb69fb74ae793191055ee3c1055":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_709f507c0aa84438a76b399ee77a856d","placeholder":"​","style":"IPY_MODEL_5c015d8f8c7e40c7b1e0f23a398e9668","value":"Map: 100%"}},"cdf12dc39c4d4b6d930b997e33b2a449":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c7e3a17d26c47009145d781f8f14e06","max":5000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6d135f2562064d42adc86a2cab618892","value":5000}},"4dfa9071423a4d46917eea9ba31f0250":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56361be501d340ab9bafd1ca9e502d47","placeholder":"​","style":"IPY_MODEL_0de5fe8bdb934e968fc20ef904dbe90c","value":" 5000/5000 [00:02&lt;00:00, 1797.90 examples/s]"}},"9ee67a0e8aef4b4fb30c21291aa744fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"709f507c0aa84438a76b399ee77a856d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c015d8f8c7e40c7b1e0f23a398e9668":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c7e3a17d26c47009145d781f8f14e06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d135f2562064d42adc86a2cab618892":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"56361be501d340ab9bafd1ca9e502d47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0de5fe8bdb934e968fc20ef904dbe90c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8757003e2704e2c9346f6969619da75":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3201b9b2ceba4b61b1d9721aa61d56c2","IPY_MODEL_2051ae6569b2497d866a898791632978","IPY_MODEL_2594778e7fa64c0fbcdbf416c537b286"],"layout":"IPY_MODEL_d6ae6168aacc42a2b8824a90ff1abf9b"}},"3201b9b2ceba4b61b1d9721aa61d56c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69281caa99994d6daef9e721fb14358f","placeholder":"​","style":"IPY_MODEL_3f98369b9b1d43db8512ed618d237467","value":"Map: 100%"}},"2051ae6569b2497d866a898791632978":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b66da9834dc248a992fb864b6b011e8a","max":5000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7008690d446a4a4e8281e76756461f70","value":5000}},"2594778e7fa64c0fbcdbf416c537b286":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c77f9d5aa54b432e863686dc76c35691","placeholder":"​","style":"IPY_MODEL_0ed04370c8ab494db2acadd6bae2cbcf","value":" 5000/5000 [00:02&lt;00:00, 1972.27 examples/s]"}},"d6ae6168aacc42a2b8824a90ff1abf9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69281caa99994d6daef9e721fb14358f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f98369b9b1d43db8512ed618d237467":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b66da9834dc248a992fb864b6b011e8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7008690d446a4a4e8281e76756461f70":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c77f9d5aa54b432e863686dc76c35691":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ed04370c8ab494db2acadd6bae2cbcf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a498a08f5efd44568f4e878013ba9904":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78a102f7f6d7432e8f7b200fa2247dcf","IPY_MODEL_bbbd18893dcd45cbb227644dcd3b357f","IPY_MODEL_61270ae93daa4eadb9a8aae49851af02"],"layout":"IPY_MODEL_debb03364bc544b39ce037e7f7b52198"}},"78a102f7f6d7432e8f7b200fa2247dcf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_476747c5df6d46adabd841b56be51f9c","placeholder":"​","style":"IPY_MODEL_5da69262a4bf4ced81fdc29e39ce96c6","value":"Map: 100%"}},"bbbd18893dcd45cbb227644dcd3b357f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8a50d04fb294e36b5dfd2d6cbc47ba4","max":5000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fa792c80a3b44fce8d064ea8636796de","value":5000}},"61270ae93daa4eadb9a8aae49851af02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2adb11b1d4c248d2a82c43b0efa71ec3","placeholder":"​","style":"IPY_MODEL_c80e8d4709984f259d115ab4e776014a","value":" 5000/5000 [00:01&lt;00:00, 3651.09 examples/s]"}},"debb03364bc544b39ce037e7f7b52198":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"476747c5df6d46adabd841b56be51f9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5da69262a4bf4ced81fdc29e39ce96c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8a50d04fb294e36b5dfd2d6cbc47ba4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa792c80a3b44fce8d064ea8636796de":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2adb11b1d4c248d2a82c43b0efa71ec3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c80e8d4709984f259d115ab4e776014a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"942c86f384844cbd9efa0bc6b23418dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_365536a7738f484e97ed641952e53061","IPY_MODEL_a033dedac3b249c79558920c74c22392","IPY_MODEL_6d29197195bf4c069db881cd5b68bab3"],"layout":"IPY_MODEL_cf3e64885b7246c58696d3165a92176f"}},"365536a7738f484e97ed641952e53061":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_993ca33c0c6a48d38986bcc76f1e42f5","placeholder":"​","style":"IPY_MODEL_a2db5c7e289a46ecac79b7581bcb83c6","value":"model.safetensors: 100%"}},"a033dedac3b249c79558920c74c22392":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c72a9ef8954141c49220f344560e02b0","max":498818054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_56d3c625eb0444058880edb1c34d8f18","value":498818054}},"6d29197195bf4c069db881cd5b68bab3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8b4c7649cf842088ebefeedb9aaf63e","placeholder":"​","style":"IPY_MODEL_7525a6d0275244bbab21985a6256b0a9","value":" 499M/499M [00:05&lt;00:00, 109MB/s]"}},"cf3e64885b7246c58696d3165a92176f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"993ca33c0c6a48d38986bcc76f1e42f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2db5c7e289a46ecac79b7581bcb83c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c72a9ef8954141c49220f344560e02b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56d3c625eb0444058880edb1c34d8f18":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c8b4c7649cf842088ebefeedb9aaf63e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7525a6d0275244bbab21985a6256b0a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Exploring Transfer Learning Performance in NLP: A Cross-Dataset Generalization Study\n","\n","This experiment aims to answer the following research questions:\n","\n","\n","1.   Which BERT family model works best for transfer learning in NLP classification tasks?\n","2.   How does model performance vary when trained on related versus unrelated datasets?\n","3.   What are the optimal fine-tuning strategies for transfer learning?\n","4.   How much data is needed to achieve effective transfer learning effects,that is, 1,000, 5,000 records or 10,000 records?\n","5.   Does the sequence of data training in continuous learning matter?\n","\n","This jupyter notebook covers the first sequence(A) using **roberta-base** where the baseline is on the primary Amazon Reviews dataset on Movies and TV, followed by further training of the baseline model on the secondary data set CDs and Vinyl dataset from a similar domain i.e. entertainment, and finally this model is evaluated on the Grocery and Gourmet review dataset which is a different domain in the food industry."],"metadata":{"id":"FSswQ3m1iVp_"}},{"cell_type":"markdown","source":["# Load Data"],"metadata":{"id":"ElUHIEaWjFsb"}},{"cell_type":"code","source":["!pip install datasets\n","!pip install evaluate\n","!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"DKmLBbwzibOK","executionInfo":{"status":"ok","timestamp":1744386498723,"user_tz":-180,"elapsed":10795,"user":{"displayName":"Hildah N","userId":"17881383761401172763"}},"outputId":"0ebbdf7d-620b-4ad2-9134-e581e324e655"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.2)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.2\n","    Uninstalling fsspec-2025.3.2:\n","      Successfully uninstalled fsspec-2025.3.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n","Collecting evaluate\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.3.2)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n","Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: evaluate\n","Successfully installed evaluate-0.4.3\n","Collecting optuna\n","  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.1)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Installing collected packages: colorlog, alembic, optuna\n","Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.2.1\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"I2FtR35qiFlZ","executionInfo":{"status":"ok","timestamp":1744386532241,"user_tz":-180,"elapsed":33516,"user":{"displayName":"Hildah N","userId":"17881383761401172763"}}},"outputs":[],"source":["import pandas as pd\n","import optuna\n","import os\n","import datasets\n","from datasets import Dataset\n","from datasets import load_dataset\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n","import numpy as np\n","import evaluate\n","from sklearn.metrics import accuracy_score,precision_recall_fscore_support,f1_score\n","from sklearn.model_selection import ParameterGrid\n","from sklearn.utils import shuffle\n","from transformers import DataCollatorWithPadding\n","import torch\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bQwoqJpRjRSp","executionInfo":{"status":"ok","timestamp":1744386555875,"user_tz":-180,"elapsed":23638,"user":{"displayName":"Hildah N","userId":"17881383761401172763"}},"outputId":"7e1775ea-7507-432c-9688-ae910c648fd6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import json\n","\n","def jsonl_to_df(file_path):\n","    \"\"\"Loads a JSONL file into a Pandas DataFrame.\n","\n","    Args:\n","        file_path: The path to the JSONL file.\n","\n","    Returns:\n","        A Pandas DataFrame containing the data from the JSONL file, or None if an error occurs.\n","    \"\"\"\n","    try:\n","        data = []\n","        with open(file_path, 'r') as f:\n","            for line in f:\n","                try:\n","                    data.append(json.loads(line))\n","                except json.JSONDecodeError as e:\n","                    print(f\"Skipping invalid JSON line: {line.strip()}\")\n","                    print(f\"Error: {e}\")\n","        df = pd.DataFrame(data)\n","        return df\n","    except FileNotFoundError:\n","        print(f\"Error: File not found at {file_path}\")\n","        return None\n","    except Exception as e:\n","        print(f\"An unexpected error occurred: {e}\")\n","        return None\n"],"metadata":{"id":"FP4BJNYKjTz6","executionInfo":{"status":"ok","timestamp":1744386555876,"user_tz":-180,"elapsed":5,"user":{"displayName":"Hildah N","userId":"17881383761401172763"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=1)\n","    # eval_metrics=metric.compute(predictions=predictions, references=labels)\n","    # f1 = f1_score(labels, predictions, average='weighted')\n","    accuracy = accuracy_score(labels, predictions)\n","    f1 = f1_score(labels, predictions, average='weighted')\n","    return {\"accuracy\": accuracy, \"f1\": f1}\n","    # return eval_metrics\n","\n","def prep_dataset(df):\n","    df = shuffle(df)\n","    df = df[df['rating'] != 3]\n","    df_subset = df[['text', 'rating']][:5000]\n","    df_subset['label'] = df['rating'].apply(lambda x: 1 if x > 4 else 0)\n","    df_subset = df_subset.drop('rating', axis=1)\n","    return df_subset\n"],"metadata":{"id":"zFJob1u8jXM2","executionInfo":{"status":"ok","timestamp":1744386555877,"user_tz":-180,"elapsed":4,"user":{"displayName":"Hildah N","userId":"17881383761401172763"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Movies and TV Dataset\n","# Load file from jsonl to df :\n","file_path = '/content/drive/MyDrive/ColabNotebooks/W266/final_project_a/shuffle_100k.jsonl'\n","df = jsonl_to_df(file_path)\n","\n","# Create binary classification\n","df_subset = prep_dataset(df)\n"],"metadata":{"id":"5M3hFUkHjaES","executionInfo":{"status":"ok","timestamp":1744386561936,"user_tz":-180,"elapsed":6058,"user":{"displayName":"Hildah N","userId":"17881383761401172763"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#  CDs and TV data set\n","# Load file from jsonl to df :\n","file_path = '/content/drive/MyDrive/ColabNotebooks/W266/final_project_a/shuffle_2_CDs_100k.jsonl'\n","df_cds = jsonl_to_df(file_path)\n","\n","# Create binary classification\n","df_cds_subset = prep_dataset(df_cds)\n"],"metadata":{"id":"JUURocVMjc7b","executionInfo":{"status":"ok","timestamp":1744386565547,"user_tz":-180,"elapsed":3609,"user":{"displayName":"Hildah N","userId":"17881383761401172763"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#  shuffle df_cds and create sample data set\n","# Load file from jsonl to df :\n","file_path = '/content/drive/MyDrive/ColabNotebooks/W266/final_project_a/shuffle_3_Food_100k.jsonl'\n","df_food = jsonl_to_df(file_path)\n","\n","df_food_subset = prep_dataset(df_food)"],"metadata":{"id":"VUA7VnQGjgAX","executionInfo":{"status":"ok","timestamp":1744386568209,"user_tz":-180,"elapsed":2660,"user":{"displayName":"Hildah N","userId":"17881383761401172763"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# roberta-base"],"metadata":{"id":"taoGR2Abqu0h"}},{"cell_type":"code","source":["BEST_MODEL_SAVE_PATH =\"drive/MyDrive/ColabNotebooks/W266/final_project_a/roberta_Movies_best\"\n","MODEL_PATH = \"drive/MyDrive/ColabNotebooks/W266/final_project_a/roberta_Movies_baseline\""],"metadata":{"id":"q96bJcVgrkNs","executionInfo":{"status":"ok","timestamp":1744386596749,"user_tz":-180,"elapsed":39,"user":{"displayName":"Hildah N","userId":"17881383761401172763"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Load tokenizer for RoBERTa\n","\n","MAX_SEQUENCE_LENGTH = 50\n","\n","# Function to preprocess (tokenize) data\n","def tokenize_function(example):\n","    review_text = example['text']\n","    encoded = tokenizer.batch_encode_plus(\n","            review_text,\n","            max_length=MAX_SEQUENCE_LENGTH,\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_token_type_ids=True,\n","            return_tensors=\"pt\"\n","        )\n","\n","    return encoded\n","\n","\n","# Apply Tokenization to each dataset\n","tokens_movies = Dataset.from_pandas(df_subset).map(tokenize_function, batched=True)\n","tokens_cds = Dataset.from_pandas(df_cds_subset).map(tokenize_function, batched=True)\n","tokens_food = Dataset.from_pandas(df_food_subset).map(tokenize_function, batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["86a0238f574f411cb1ec5c5c879d6cc9","4affbcb69fb74ae793191055ee3c1055","cdf12dc39c4d4b6d930b997e33b2a449","4dfa9071423a4d46917eea9ba31f0250","9ee67a0e8aef4b4fb30c21291aa744fc","709f507c0aa84438a76b399ee77a856d","5c015d8f8c7e40c7b1e0f23a398e9668","6c7e3a17d26c47009145d781f8f14e06","6d135f2562064d42adc86a2cab618892","56361be501d340ab9bafd1ca9e502d47","0de5fe8bdb934e968fc20ef904dbe90c","c8757003e2704e2c9346f6969619da75","3201b9b2ceba4b61b1d9721aa61d56c2","2051ae6569b2497d866a898791632978","2594778e7fa64c0fbcdbf416c537b286","d6ae6168aacc42a2b8824a90ff1abf9b","69281caa99994d6daef9e721fb14358f","3f98369b9b1d43db8512ed618d237467","b66da9834dc248a992fb864b6b011e8a","7008690d446a4a4e8281e76756461f70","c77f9d5aa54b432e863686dc76c35691","0ed04370c8ab494db2acadd6bae2cbcf","a498a08f5efd44568f4e878013ba9904","78a102f7f6d7432e8f7b200fa2247dcf","bbbd18893dcd45cbb227644dcd3b357f","61270ae93daa4eadb9a8aae49851af02","debb03364bc544b39ce037e7f7b52198","476747c5df6d46adabd841b56be51f9c","5da69262a4bf4ced81fdc29e39ce96c6","c8a50d04fb294e36b5dfd2d6cbc47ba4","fa792c80a3b44fce8d064ea8636796de","2adb11b1d4c248d2a82c43b0efa71ec3","c80e8d4709984f259d115ab4e776014a"]},"id":"jmSWxGfKxYLm","executionInfo":{"status":"ok","timestamp":1744386701441,"user_tz":-180,"elapsed":7299,"user":{"displayName":"Hildah N","userId":"17881383761401172763"}},"outputId":"6e2d1343-984d-4b21-ebd9-2c9d02c9b639"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86a0238f574f411cb1ec5c5c879d6cc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8757003e2704e2c9346f6969619da75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a498a08f5efd44568f4e878013ba9904"}},"metadata":{}}]},{"cell_type":"code","source":["# Baseline\n","model_name = \"roberta-base\"\n","\n","model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n","\n","split_datasets = tokens_movies.train_test_split(test_size=0.2)\n","\n","# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    evaluation_strategy=\"epoch\"\n",")\n","\n","\n","# Create Trainer instance\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=split_datasets[\"train\"],\n","    eval_dataset=split_datasets[\"test\"],\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer,\n","    data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n",")\n","\n","# Train the model\n","trainer.train()\n","\n","# Evaluate the model\n","trainer.evaluate()\n","\n","# Save the trained model\n","trainer.save_model(MODEL_PATH)\n","tokenizer.save_pretrained(MODEL_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":484,"referenced_widgets":["942c86f384844cbd9efa0bc6b23418dc","365536a7738f484e97ed641952e53061","a033dedac3b249c79558920c74c22392","6d29197195bf4c069db881cd5b68bab3","cf3e64885b7246c58696d3165a92176f","993ca33c0c6a48d38986bcc76f1e42f5","a2db5c7e289a46ecac79b7581bcb83c6","c72a9ef8954141c49220f344560e02b0","56d3c625eb0444058880edb1c34d8f18","c8b4c7649cf842088ebefeedb9aaf63e","7525a6d0275244bbab21985a6256b0a9"]},"id":"zNhSQoUuj5hz","executionInfo":{"status":"ok","timestamp":1744387327461,"user_tz":-180,"elapsed":254944,"user":{"displayName":"Hildah N","userId":"17881383761401172763"}},"outputId":"d82d2656-a1d5-4941-e9df-aa7bb5f88ef0"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"942c86f384844cbd9efa0bc6b23418dc"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-14-2e8156077bb8>:25: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [750/750 03:58, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.517090</td>\n","      <td>0.768000</td>\n","      <td>0.762890</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.501500</td>\n","      <td>0.461612</td>\n","      <td>0.799000</td>\n","      <td>0.798897</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.501500</td>\n","      <td>0.466616</td>\n","      <td>0.827000</td>\n","      <td>0.821164</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [63/63 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["('drive/MyDrive/ColabNotebooks/W266/final_project_a/roberta_Movies_baseline/tokenizer_config.json',\n"," 'drive/MyDrive/ColabNotebooks/W266/final_project_a/roberta_Movies_baseline/special_tokens_map.json',\n"," 'drive/MyDrive/ColabNotebooks/W266/final_project_a/roberta_Movies_baseline/vocab.json',\n"," 'drive/MyDrive/ColabNotebooks/W266/final_project_a/roberta_Movies_baseline/merges.txt',\n"," 'drive/MyDrive/ColabNotebooks/W266/final_project_a/roberta_Movies_baseline/added_tokens.json',\n"," 'drive/MyDrive/ColabNotebooks/W266/final_project_a/roberta_Movies_baseline/tokenizer.json')"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["## Hyperparameter tuning"],"metadata":{"id":"_BXRWr5GrzkT"}},{"cell_type":"code","source":["#Fine tuning\n","best_accuracy = 0.0\n","best_trainer = None\n","\n","def objective(trial):\n","    global best_accuracy, best_trainer\n","\n","    # Load the saved model\n","    model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH, num_labels=2)\n","    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n","\n","    # Define hyperparameters to be optimized\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True)\n","    per_device_train_batch_size = trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16])\n","    num_train_epochs = trial.suggest_int(\"num_train_epochs\", 1, 3)\n","    weight_decay = trial.suggest_float(\"weight_decay\", 0.01, 0.1)\n","\n","    # Define training arguments\n","    training_args = TrainingArguments(\n","        output_dir=BEST_MODEL_SAVE_PATH,\n","        learning_rate=learning_rate,\n","        per_device_train_batch_size=per_device_train_batch_size,\n","        per_device_eval_batch_size=16,\n","        num_train_epochs=num_train_epochs,\n","        weight_decay=weight_decay,\n","        evaluation_strategy=\"epoch\",\n","    )\n","\n","    # Create Trainer instance\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=split_datasets[\"train\"],\n","        eval_dataset=split_datasets[\"test\"],\n","        compute_metrics=compute_metrics,\n","        tokenizer=tokenizer,\n","        data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n","    )\n","\n","    # Train the model\n","    trainer.train()\n","\n","    result = trainer.evaluate()\n","    accuracy = result[\"eval_accuracy\"]\n","\n","    # Save the best model\n","    if accuracy > best_accuracy:\n","        best_accuracy = accuracy\n","        best_trainer = trainer\n","\n","    return accuracy\n","\n","# Create Optuna study\n","study = optuna.create_study(direction=\"maximize\")  # Maximize the evaluation metric\n","study.optimize(objective, n_trials=10)  # Run 10 trials\n","\n","if best_trainer:\n","    best_trainer.save_model(BEST_MODEL_SAVE_PATH)\n","    tokenizer.save_pretrained(BEST_MODEL_SAVE_PATH)\n","    print(f\"Best model saved to: {BEST_MODEL_SAVE_PATH}\")\n","\n","# Print best hyperparameters\n","print(\"Best trial:\")\n","trial = study.best_trial\n","print(f\"  Value: {trial.value}\")\n","print(f\"  Params: \")\n","for key, value in trial.params.items():\n","    print(f\"    {key}: {value}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"KCQkApheZ9nM","executionInfo":{"status":"ok","timestamp":1744389221999,"user_tz":-180,"elapsed":1825209,"user":{"displayName":"Hildah N","userId":"17881383761401172763"}},"outputId":"4876706b-6082-406b-8269-ea00550fd3fa"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-04-11 16:03:16,687] A new study created in memory with name: no-name-96e97113-fcc3-4040-9d37-3af02fe1fa51\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-15-b6694d1df841>:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [750/750 02:41, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.467053</td>\n","      <td>0.829000</td>\n","      <td>0.820591</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.291700</td>\n","      <td>0.533473</td>\n","      <td>0.819000</td>\n","      <td>0.808884</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.291700</td>\n","      <td>0.710415</td>\n","      <td>0.810000</td>\n","      <td>0.807250</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [63/63 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-04-11 16:06:02,877] Trial 0 finished with value: 0.81 and parameters: {'learning_rate': 1.217257703002136e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 3, 'weight_decay': 0.0946548734592278}. Best is trial 0 with value: 0.81.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-15-b6694d1df841>:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1500/1500 04:13, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.455600</td>\n","      <td>0.521926</td>\n","      <td>0.779000</td>\n","      <td>0.730928</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.399400</td>\n","      <td>0.474608</td>\n","      <td>0.839000</td>\n","      <td>0.828868</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.333000</td>\n","      <td>0.607877</td>\n","      <td>0.837000</td>\n","      <td>0.828985</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [63/63 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-04-11 16:10:21,971] Trial 1 finished with value: 0.837 and parameters: {'learning_rate': 3.294688780599071e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 3, 'weight_decay': 0.030644514793878787}. Best is trial 1 with value: 0.837.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-15-b6694d1df841>:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [750/750 03:17, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.471538</td>\n","      <td>0.823000</td>\n","      <td>0.806998</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.318200</td>\n","      <td>0.524917</td>\n","      <td>0.817000</td>\n","      <td>0.812114</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.318200</td>\n","      <td>0.688194</td>\n","      <td>0.810000</td>\n","      <td>0.806306</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [63/63 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-04-11 16:13:46,491] Trial 2 finished with value: 0.81 and parameters: {'learning_rate': 2.6288520029853065e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 3, 'weight_decay': 0.09904442152369852}. Best is trial 1 with value: 0.837.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-15-b6694d1df841>:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 03:16, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.388900</td>\n","      <td>0.541365</td>\n","      <td>0.815000</td>\n","      <td>0.798275</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.338400</td>\n","      <td>0.682768</td>\n","      <td>0.828000</td>\n","      <td>0.821304</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [63/63 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-04-11 16:17:08,314] Trial 3 finished with value: 0.828 and parameters: {'learning_rate': 1.1965991303534613e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 2, 'weight_decay': 0.020446327677859595}. Best is trial 1 with value: 0.837.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-15-b6694d1df841>:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [250/250 01:24, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.512250</td>\n","      <td>0.830000</td>\n","      <td>0.820644</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [63/63 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-04-11 16:18:39,985] Trial 4 finished with value: 0.83 and parameters: {'learning_rate': 1.3586177981498592e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 1, 'weight_decay': 0.016860649788603122}. Best is trial 1 with value: 0.837.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-15-b6694d1df841>:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [750/750 03:03, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.513385</td>\n","      <td>0.783000</td>\n","      <td>0.781973</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.344900</td>\n","      <td>0.552129</td>\n","      <td>0.808000</td>\n","      <td>0.803263</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.344900</td>\n","      <td>0.616999</td>\n","      <td>0.815000</td>\n","      <td>0.807938</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [63/63 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-04-11 16:21:52,883] Trial 5 finished with value: 0.815 and parameters: {'learning_rate': 4.082579851517658e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 3, 'weight_decay': 0.027053310707729983}. Best is trial 1 with value: 0.837.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-15-b6694d1df841>:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 03:09, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.473600</td>\n","      <td>0.517953</td>\n","      <td>0.757000</td>\n","      <td>0.763416</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.408200</td>\n","      <td>0.520738</td>\n","      <td>0.823000</td>\n","      <td>0.815975</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [63/63 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-04-11 16:25:10,355] Trial 6 finished with value: 0.823 and parameters: {'learning_rate': 3.954902455853101e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 2, 'weight_decay': 0.016291680490638675}. Best is trial 1 with value: 0.837.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-15-b6694d1df841>:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [500/500 01:31, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.389100</td>\n","      <td>0.600108</td>\n","      <td>0.826000</td>\n","      <td>0.817868</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [63/63 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-04-11 16:26:49,360] Trial 7 finished with value: 0.826 and parameters: {'learning_rate': 1.221495682723614e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 1, 'weight_decay': 0.011349745739749098}. Best is trial 1 with value: 0.837.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-15-b6694d1df841>:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1500/1500 04:19, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.420300</td>\n","      <td>0.560219</td>\n","      <td>0.809000</td>\n","      <td>0.794837</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.341800</td>\n","      <td>0.576576</td>\n","      <td>0.823000</td>\n","      <td>0.812178</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.292100</td>\n","      <td>0.680195</td>\n","      <td>0.818000</td>\n","      <td>0.810915</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [63/63 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-04-11 16:31:16,222] Trial 8 finished with value: 0.818 and parameters: {'learning_rate': 1.8369253102321457e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 3, 'weight_decay': 0.08589974563668094}. Best is trial 1 with value: 0.837.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-15-b6694d1df841>:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [500/500 01:51, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.460947</td>\n","      <td>0.827000</td>\n","      <td>0.818493</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.292200</td>\n","      <td>0.620742</td>\n","      <td>0.825000</td>\n","      <td>0.820088</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [63/63 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-04-11 16:33:39,146] Trial 9 finished with value: 0.825 and parameters: {'learning_rate': 1.5251060926134987e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 2, 'weight_decay': 0.030500118381803817}. Best is trial 1 with value: 0.837.\n"]},{"output_type":"stream","name":"stdout","text":["Best model saved to: drive/MyDrive/ColabNotebooks/W266/final_project_a/roberta_Movies_best\n","Best trial:\n","  Value: 0.837\n","  Params: \n","    learning_rate: 3.294688780599071e-05\n","    per_device_train_batch_size: 8\n","    num_train_epochs: 3\n","    weight_decay: 0.030644514793878787\n"]}]},{"cell_type":"markdown","source":["## Train on CD and Vinyl Dataset\n"],"metadata":{"id":"7HpwSg3gdK2d"}},{"cell_type":"code","source":["# Load best model\n","model = AutoModelForSequenceClassification.from_pretrained(BEST_MODEL_SAVE_PATH)\n","tokenizer = AutoTokenizer.from_pretrained(BEST_MODEL_SAVE_PATH)\n","TRAINING_ARGS=f\"{BEST_MODEL_SAVE_PATH}/training_args.bin\"\n","CD_MODEL_PATH = \"drive/MyDrive/ColabNotebooks/W266/final_project_a/roberta_Movies_CD\"\n","\n","# Split the data\n","split_datasets = tokens_cds.train_test_split(test_size=0.2)\n","\n","training_args = torch.load(TRAINING_ARGS, weights_only=False)\n","\n","# Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=split_datasets[\"train\"],\n","    eval_dataset=split_datasets[\"test\"],\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# Train\n","trainer.train()\n","\n","# save model\n","\n","model.save_pretrained(CD_MODEL_PATH)\n","tokenizer.save_pretrained(CD_MODEL_PATH)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"id":"mL4vfXKRdPWW","executionInfo":{"status":"ok","timestamp":1744389510705,"user_tz":-180,"elapsed":273461,"user":{"displayName":"Hildah N","userId":"17881383761401172763"}},"outputId":"759c0ef8-5c14-430d-ac3b-97c3ce5508ad"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-16-d79a8e5876e3>:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1500/1500 04:14, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.481300</td>\n","      <td>0.488785</td>\n","      <td>0.771000</td>\n","      <td>0.782022</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.429100</td>\n","      <td>0.450715</td>\n","      <td>0.821000</td>\n","      <td>0.812434</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.369900</td>\n","      <td>0.529551</td>\n","      <td>0.815000</td>\n","      <td>0.807443</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["('drive/MyDrive/ColabNotebooks/W266/final_project_a/roberta_Movies_CD/tokenizer_config.json',\n"," 'drive/MyDrive/ColabNotebooks/W266/final_project_a/roberta_Movies_CD/special_tokens_map.json',\n"," 'drive/MyDrive/ColabNotebooks/W266/final_project_a/roberta_Movies_CD/vocab.json',\n"," 'drive/MyDrive/ColabNotebooks/W266/final_project_a/roberta_Movies_CD/merges.txt',\n"," 'drive/MyDrive/ColabNotebooks/W266/final_project_a/roberta_Movies_CD/added_tokens.json',\n"," 'drive/MyDrive/ColabNotebooks/W266/final_project_a/roberta_Movies_CD/tokenizer.json')"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["## Evaluate on Food"],"metadata":{"id":"OJ9Qv531fSfE"}},{"cell_type":"code","source":["\n","model = AutoModelForSequenceClassification.from_pretrained(CD_MODEL_PATH)\n","tokenizer = AutoTokenizer.from_pretrained(CD_MODEL_PATH)\n","\n","# Train\n","trainer = Trainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","\n","results = trainer.evaluate(eval_dataset=tokens_food)\n","print(\"\\nEvaluation Results:\", results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"id":"WqNi2WX7fY14","executionInfo":{"status":"ok","timestamp":1744389595859,"user_tz":-180,"elapsed":19188,"user":{"displayName":"Hildah N","userId":"17881383761401172763"}},"outputId":"ef200f8f-d84b-4e01-9f40-a64cc88b21e9"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-17-a87ac7cfe94c>:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [625/625 00:16]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Evaluation Results: {'eval_loss': 0.45874881744384766, 'eval_model_preparation_time': 0.0057, 'eval_accuracy': 0.833, 'eval_f1': 0.8304098844719083, 'eval_runtime': 16.2927, 'eval_samples_per_second': 306.886, 'eval_steps_per_second': 38.361}\n"]}]}]}